use anyhow::Result;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};

/// ç¼“å­˜æ€§èƒ½ç›‘æ§å™¨
#[derive(Clone)]
pub struct CachePerformanceMonitor {
    metrics: Arc<CacheMetrics>,
}

/// ç¼“å­˜æŒ‡æ ‡
#[derive(Default)]
pub struct CacheMetrics {
    /// ç¼“å­˜å‘½ä¸­æ¬¡æ•°
    pub cache_hits: AtomicU64,
    /// ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°
    pub cache_misses: AtomicU64,
    /// ç¼“å­˜å†™å…¥æ¬¡æ•°
    pub cache_writes: AtomicU64,
    /// ç¼“å­˜é”™è¯¯æ¬¡æ•°
    pub cache_errors: AtomicU64,
    /// æ€»èŠ‚çœçš„æ¨ç†æ—¶é—´ï¼ˆç§’ï¼‰
    pub total_inference_time_saved: AtomicU64,
    /// æ€»èŠ‚çœçš„æ¨ç†æˆæœ¬ï¼ˆä¼°ç®—ï¼‰
    pub total_cost_saved: AtomicU64,
}

/// ç¼“å­˜æ€§èƒ½æŠ¥å‘Š
#[derive(Debug, Serialize, Deserialize)]
pub struct CachePerformanceReport {
    /// ç¼“å­˜å‘½ä¸­ç‡
    pub hit_rate: f64,
    /// æ€»ç¼“å­˜æ“ä½œæ¬¡æ•°
    pub total_operations: u64,
    /// ç¼“å­˜å‘½ä¸­æ¬¡æ•°
    pub cache_hits: u64,
    /// ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°
    pub cache_misses: u64,
    /// ç¼“å­˜å†™å…¥æ¬¡æ•°
    pub cache_writes: u64,
    /// ç¼“å­˜é”™è¯¯æ¬¡æ•°
    pub cache_errors: u64,
    /// èŠ‚çœçš„æ¨ç†æ—¶é—´ï¼ˆç§’ï¼‰
    pub inference_time_saved: f64,
    /// èŠ‚çœçš„æ¨ç†æˆæœ¬ï¼ˆç¾å…ƒï¼Œä¼°ç®—ï¼‰
    pub cost_saved: f64,
    /// æ€§èƒ½æå‡ç™¾åˆ†æ¯”
    pub performance_improvement: f64,
    /// åˆ†ç±»ç»Ÿè®¡
    pub category_stats: HashMap<String, CategoryPerformanceStats>,
}

/// åˆ†ç±»æ€§èƒ½ç»Ÿè®¡
#[derive(Debug, Serialize, Deserialize)]
pub struct CategoryPerformanceStats {
    pub hits: u64,
    pub misses: u64,
    pub hit_rate: f64,
    pub time_saved: f64,
    pub cost_saved: f64,
}

impl CachePerformanceMonitor {
    pub fn new() -> Self {
        Self {
            metrics: Arc::new(CacheMetrics::default()),
        }
    }

    /// è®°å½•ç¼“å­˜å‘½ä¸­
    pub fn record_cache_hit(&self, category: &str, inference_time_saved: Duration) {
        self.metrics.cache_hits.fetch_add(1, Ordering::Relaxed);
        self.metrics.total_inference_time_saved.fetch_add(
            inference_time_saved.as_millis() as u64,
            Ordering::Relaxed,
        );
        
        // ä¼°ç®—èŠ‚çœçš„æˆæœ¬ï¼ˆåŸºäºGPT-4çš„å®šä»·ï¼‰
        let estimated_cost_saved = self.estimate_cost_saved(inference_time_saved);
        self.metrics.total_cost_saved.fetch_add(
            (estimated_cost_saved * 1000.0) as u64, // å­˜å‚¨ä¸ºæ¯«ç¾å…ƒ
            Ordering::Relaxed,
        );

        println!("   ğŸ’° ç¼“å­˜å‘½ä¸­ [{}] - èŠ‚çœæ¨ç†æ—¶é—´: {:.2}ç§’, ä¼°ç®—èŠ‚çœæˆæœ¬: ${:.4}", 
                category, 
                inference_time_saved.as_secs_f64(),
                estimated_cost_saved);
    }

    /// è®°å½•ç¼“å­˜æœªå‘½ä¸­
    pub fn record_cache_miss(&self, category: &str) {
        self.metrics.cache_misses.fetch_add(1, Ordering::Relaxed);
        println!("   ğŸ” ç¼“å­˜æœªå‘½ä¸­ [{}] - éœ€è¦è¿›è¡ŒAIæ¨ç†", category);
    }

    /// è®°å½•ç¼“å­˜å†™å…¥
    pub fn record_cache_write(&self, category: &str) {
        self.metrics.cache_writes.fetch_add(1, Ordering::Relaxed);
        println!("   ğŸ’¾ ç¼“å­˜å†™å…¥ [{}] - ç»“æœå·²ç¼“å­˜", category);
    }

    /// è®°å½•ç¼“å­˜é”™è¯¯
    pub fn record_cache_error(&self, category: &str, error: &str) {
        self.metrics.cache_errors.fetch_add(1, Ordering::Relaxed);
        eprintln!("   âŒ ç¼“å­˜é”™è¯¯ [{}]: {}", category, error);
    }

    /// ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    pub fn generate_report(&self) -> CachePerformanceReport {
        let hits = self.metrics.cache_hits.load(Ordering::Relaxed);
        let misses = self.metrics.cache_misses.load(Ordering::Relaxed);
        let writes = self.metrics.cache_writes.load(Ordering::Relaxed);
        let errors = self.metrics.cache_errors.load(Ordering::Relaxed);
        let total_operations = hits + misses;
        
        let hit_rate = if total_operations > 0 {
            hits as f64 / total_operations as f64
        } else {
            0.0
        };

        let inference_time_saved = self.metrics.total_inference_time_saved.load(Ordering::Relaxed) as f64 / 1000.0; // è½¬æ¢ä¸ºç§’
        let cost_saved = self.metrics.total_cost_saved.load(Ordering::Relaxed) as f64 / 1000.0; // è½¬æ¢ä¸ºç¾å…ƒ

        let performance_improvement = if misses > 0 {
            (hits as f64 / (hits + misses) as f64) * 100.0
        } else {
            0.0
        };

        CachePerformanceReport {
            hit_rate,
            total_operations,
            cache_hits: hits,
            cache_misses: misses,
            cache_writes: writes,
            cache_errors: errors,
            inference_time_saved,
            cost_saved,
            performance_improvement,
            category_stats: HashMap::new(), // TODO: å®ç°åˆ†ç±»ç»Ÿè®¡
        }
    }

    /// æ‰“å°æ€§èƒ½æ‘˜è¦
    pub fn print_performance_summary(&self) {
        let report = self.generate_report();
        
        println!("\nğŸ“Š ç¼“å­˜æ€§èƒ½æ‘˜è¦:");
        println!("   ğŸ¯ ç¼“å­˜å‘½ä¸­ç‡: {:.1}%", report.hit_rate * 100.0);
        println!("   ğŸ“ˆ æ€»æ“ä½œæ¬¡æ•°: {}", report.total_operations);
        println!("   âœ… ç¼“å­˜å‘½ä¸­: {} æ¬¡", report.cache_hits);
        println!("   âŒ ç¼“å­˜æœªå‘½ä¸­: {} æ¬¡", report.cache_misses);
        println!("   ğŸ’¾ ç¼“å­˜å†™å…¥: {} æ¬¡", report.cache_writes);
        
        if report.cache_errors > 0 {
            println!("   âš ï¸  ç¼“å­˜é”™è¯¯: {} æ¬¡", report.cache_errors);
        }
        
        println!("   â±ï¸  èŠ‚çœæ¨ç†æ—¶é—´: {:.1} ç§’", report.inference_time_saved);
        println!("   ğŸ’° ä¼°ç®—èŠ‚çœæˆæœ¬: ${:.2}", report.cost_saved);
        
        if report.performance_improvement > 0.0 {
            println!("   ğŸš€ æ€§èƒ½æå‡: {:.1}%", report.performance_improvement);
        }
    }

    /// ä¼°ç®—èŠ‚çœçš„æˆæœ¬ï¼ˆåŸºäºGPT-4å®šä»·ï¼‰
    fn estimate_cost_saved(&self, inference_time: Duration) -> f64 {
        // å‡è®¾å¹³å‡æ¯æ¬¡æ¨ç†éœ€è¦1000ä¸ªtokenè¾“å…¥ï¼Œ500ä¸ªtokenè¾“å‡º
        // GPT-4 å®šä»·ï¼šè¾“å…¥ $0.03/1K tokensï¼Œè¾“å‡º $0.06/1K tokens
        let input_tokens = 1000.0;
        let output_tokens = 500.0;
        let input_cost_per_1k = 0.03;
        let output_cost_per_1k = 0.06;
        
        let total_cost = (input_tokens / 1000.0) * input_cost_per_1k + 
                        (output_tokens / 1000.0) * output_cost_per_1k;
        
        total_cost
    }

    /// é‡ç½®ç»Ÿè®¡ä¿¡æ¯
    pub fn reset_metrics(&self) {
        self.metrics.cache_hits.store(0, Ordering::Relaxed);
        self.metrics.cache_misses.store(0, Ordering::Relaxed);
        self.metrics.cache_writes.store(0, Ordering::Relaxed);
        self.metrics.cache_errors.store(0, Ordering::Relaxed);
        self.metrics.total_inference_time_saved.store(0, Ordering::Relaxed);
        self.metrics.total_cost_saved.store(0, Ordering::Relaxed);
    }
}

impl Default for CachePerformanceMonitor {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::time::Duration;

    #[test]
    fn test_cache_performance_monitor() {
        let monitor = CachePerformanceMonitor::new();
        
        // æ¨¡æ‹Ÿä¸€äº›ç¼“å­˜æ“ä½œ
        monitor.record_cache_hit("test", Duration::from_secs(2));
        monitor.record_cache_miss("test");
        monitor.record_cache_write("test");
        
        let report = monitor.generate_report();
        assert_eq!(report.cache_hits, 1);
        assert_eq!(report.cache_misses, 1);
        assert_eq!(report.cache_writes, 1);
        assert_eq!(report.hit_rate, 0.5);
    }
}