use anyhow::Result;
use serde::{Deserialize, Serialize};
use std::path::PathBuf;
use std::time::Instant;

use crate::agents::documentation_agent::DocumentationResult;
use crate::agents::research_agent::ResearchResult;
use crate::agents::{DocumentationAgent, PreprocessingAgent, ResearchAgent};
use crate::config::Config;

/// å·¥ä½œæµå¼•æ“
pub struct WorkflowEngine {
    config: Config,
    preprocessing_agent: PreprocessingAgent,
}

/// å·¥ä½œæµæ‰§è¡Œç»“æœ
#[derive(Debug, Serialize, Deserialize)]
pub struct WorkflowResult {
    pub processed_files: usize,
    pub core_components: usize,
    pub generated_documents: usize,
    pub output_path: PathBuf,
    pub total_time: f64,
    pub stage_times: StageTimings,
    pub success: bool,
    pub summary: String,
}

/// å„é˜¶æ®µè€—æ—¶
#[derive(Debug, Serialize, Deserialize)]
pub struct StageTimings {
    pub preprocessing: f64,
    pub research: f64,
    pub documentation: f64,
}

impl WorkflowEngine {
    pub async fn new(config: Config) -> Result<Self> {
        println!("ğŸš€ åˆå§‹åŒ–å·¥ä½œæµå¼•æ“...");

        // åˆ›å»ºé¢„å¤„ç†Agent
        let preprocessing_agent = PreprocessingAgent::new(config.clone()).await?;

        Ok(Self {
            config,
            preprocessing_agent,
        })
    }

    /// æ‰§è¡Œå®Œæ•´çš„å·¥ä½œæµ
    pub async fn execute(&mut self) -> Result<WorkflowResult> {
        let start_time = Instant::now();
        let mut stage_times = StageTimings {
            preprocessing: 0.0,
            research: 0.0,
            documentation: 0.0,
        };

        println!("ğŸ”„ å¯åŠ¨Lithoåˆ†æå¼•æ“...");

        // æ¸…ç†è¾“å‡ºç›®å½•ï¼Œç¡®ä¿åªæœ‰æœ€æ–°çš„æ–‡æ¡£
        self.prepare_output_directories().await?;

        // é˜¶æ®µ1: é¡¹ç›®é¢„å¤„ç†
        println!("\nğŸ“‹ é˜¶æ®µ1: é¡¹ç›®é¢„å¤„ç†");
        let preprocessing_start = Instant::now();
        let preprocessing_result = self.preprocessing_agent.preprocess().await?;
        stage_times.preprocessing = preprocessing_start.elapsed().as_secs_f64();

        println!("âœ… é¢„å¤„ç†å®Œæˆ:");
        println!(
            "   - å¤„ç†æ–‡ä»¶: {}",
            preprocessing_result.project_structure.total_files
        );
        println!(
            "   - æ ¸å¿ƒç»„ä»¶: {}",
            preprocessing_result.core_components.len()
        );
        println!("   - è€—æ—¶: {:.2}ç§’", stage_times.preprocessing);

        // é˜¶æ®µ2: è°ƒç ”æ–‡æ¡£ç”Ÿæˆ
        println!("\nğŸ“š é˜¶æ®µ2: è°ƒç ”æ–‡æ¡£ç”Ÿæˆ");
        let research_start = Instant::now();
        let research_agent = ResearchAgent::new(self.config.clone()).await?;
        let research_result = research_agent
            .generate_research(&preprocessing_result)
            .await?;
        stage_times.research = research_start.elapsed().as_secs_f64();

        println!("âœ… è°ƒç ”æ–‡æ¡£ç”Ÿæˆå®Œæˆ:");
        println!("   - ç”ŸæˆæŠ¥å‘Š: {}", research_result.reports.len());
        println!("   - è€—æ—¶: {:.2}ç§’", stage_times.research);

        // é˜¶æ®µ3: æœ€ç»ˆçŸ¥è¯†åº“æ–‡æ¡£ç”Ÿæˆ
        println!("\nğŸ“– é˜¶æ®µ3: çŸ¥è¯†åº“æ–‡æ¡£ç”Ÿæˆ");
        let documentation_start = Instant::now();
        let documentation_agent = DocumentationAgent::new(self.config.clone()).await?;
        let documentation_result = documentation_agent
            .generate_documentation(&preprocessing_result, &research_result)
            .await?;
        stage_times.documentation = documentation_start.elapsed().as_secs_f64();

        println!("âœ… çŸ¥è¯†åº“æ–‡æ¡£ç”Ÿæˆå®Œæˆ:");
        println!("   - ç”Ÿæˆæ–‡æ¡£: {}", documentation_result.documents.len());
        println!("   - è€—æ—¶: {:.2}ç§’", stage_times.documentation);

        // ä¿å­˜ç»“æœåˆ°è¾“å‡ºç›®å½•
        self.save_results(
            &preprocessing_result,
            &research_result,
            &documentation_result,
        )
        .await?;

        let total_time = start_time.elapsed().as_secs_f64();

        let result = WorkflowResult {
            processed_files: preprocessing_result.project_structure.total_files,
            core_components: preprocessing_result.core_components.len(),
            generated_documents: documentation_result.documents.len(),
            output_path: self.config.output_path.clone(),
            total_time,
            stage_times,
            success: true,
            summary: self.generate_workflow_summary(
                &preprocessing_result,
                &research_result,
                &documentation_result,
            ),
        };

        println!("\nğŸ‰ å·¥ä½œæµæ‰§è¡Œå®Œæˆ!");
        println!("ğŸ“Š æ€»è€—æ—¶: {:.2}ç§’", total_time);

        Ok(result)
    }

    /// å‡†å¤‡è¾“å‡ºç›®å½•
    async fn prepare_output_directories(&self) -> Result<()> {
        use tokio::fs;

        // ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        fs::create_dir_all(&self.config.output_path).await?;

        // ç¡®ä¿å†…éƒ¨å·¥ä½œç›®å½•å­˜åœ¨
        fs::create_dir_all(&self.config.internal_path).await?;
        fs::create_dir_all(&self.config.get_process_data_path()).await?;
        fs::create_dir_all(&self.config.get_temp_path()).await?;

        // æ¸…ç†è¾“å‡ºç›®å½•ä¸­çš„æ—§æ–‡æ¡£æ–‡ä»¶ï¼ˆä¿ç•™ç”¨æˆ·å¯èƒ½æ‰‹åŠ¨æ·»åŠ çš„æ–‡ä»¶ï¼‰
        if self.config.output_path.exists() {
            let mut entries = fs::read_dir(&self.config.output_path).await?;
            while let Some(entry) = entries.next_entry().await? {
                let path = entry.path();
                if path.is_file() {
                    if let Some(extension) = path.extension() {
                        if extension == "md" || extension == "html" {
                            // åªåˆ é™¤å¯èƒ½æ˜¯ä¹‹å‰ç”Ÿæˆçš„æ–‡æ¡£æ–‡ä»¶
                            if let Some(filename) = path.file_name() {
                                let filename_str = filename.to_string_lossy();
                                if filename_str.starts_with("README")
                                    || filename_str.contains("architecture")
                                    || filename_str.contains("component")
                                    || filename_str.contains("api")
                                {
                                    let _ = fs::remove_file(&path).await; // å¿½ç•¥åˆ é™¤é”™è¯¯
                                }
                            }
                        }
                    }
                }
            }
        }

        println!("ğŸ“ è¾“å‡ºç›®å½•å·²å‡†å¤‡: {}", self.config.output_path.display());
        println!("ğŸ”§ å†…éƒ¨å·¥ä½œç›®å½•: {}", self.config.internal_path.display());

        Ok(())
    }

    async fn save_results(
        &self,
        preprocessing_result: &crate::agents::preprocessing_agent::PreprocessingResult,
        research_result: &ResearchResult,
        documentation_result: &DocumentationResult,
    ) -> Result<()> {
        use tokio::fs;

        // ç¡®ä¿è¾“å‡ºç›®å½•å’Œå†…éƒ¨å·¥ä½œç›®å½•å­˜åœ¨
        fs::create_dir_all(&self.config.output_path).await?;
        let process_data_path = self.config.get_process_data_path();
        fs::create_dir_all(&process_data_path).await?;

        // ä¿å­˜è¿‡ç¨‹æ•°æ®åˆ° .litho/process/ ç›®å½•
        let preprocessing_path = process_data_path.join("preprocessing_result.json");
        let preprocessing_json = serde_json::to_string_pretty(preprocessing_result)?;
        fs::write(preprocessing_path, preprocessing_json).await?;

        let research_path = process_data_path.join("research_result.json");
        let research_json = serde_json::to_string_pretty(research_result)?;
        fs::write(research_path, research_json).await?;

        // ä¿å­˜å·¥ä½œæµæ‰§è¡Œä¿¡æ¯åˆ°å†…éƒ¨ç›®å½•
        let workflow_info_path = process_data_path.join("workflow_info.json");
        let workflow_info = serde_json::json!({
            "execution_time": chrono::Utc::now().to_rfc3339(),
            "processed_files": preprocessing_result.project_structure.total_files,
            "core_components": preprocessing_result.core_components.len(),
            "generated_documents": documentation_result.documents.len(),
            "config": {
                "project_path": self.config.project_path,
                "output_path": self.config.output_path,
                "document_format": self.config.document_format
            }
        });
        fs::write(
            workflow_info_path,
            serde_json::to_string_pretty(&workflow_info)?,
        )
        .await?;

        // ä¿å­˜æœ€ç»ˆæ–‡æ¡£åˆ°è¾“å‡ºç›®å½•ï¼ˆç”¨æˆ·å¯è§ï¼‰
        for document in &documentation_result.documents {
            let doc_path = self.config.output_path.join(&document.filename);
            fs::write(doc_path, &document.content).await?;
        }

        // ä¿å­˜å·¥ä½œæµæ‘˜è¦åˆ°è¾“å‡ºç›®å½•ä¸‹çš„`litho_work_summary.md`
        let summary_path = self.config.output_path.join("litho_work_summary.md");
        let summary_content = self.generate_markdown_summary(
            preprocessing_result,
            research_result,
            documentation_result,
        );
        fs::write(summary_path, summary_content).await?;

        println!("ğŸ“ è¿‡ç¨‹æ•°æ®å·²ä¿å­˜åˆ°: {}", process_data_path.display());
        println!("ğŸ“„ æœ€ç»ˆæ–‡æ¡£å·²ä¿å­˜åˆ°: {}", self.config.output_path.display());

        Ok(())
    }

    fn generate_workflow_summary(
        &self,
        preprocessing_result: &crate::agents::preprocessing_agent::PreprocessingResult,
        research_result: &ResearchResult,
        documentation_result: &DocumentationResult,
    ) -> String {
        format!(
            "DeepWikiå·¥ä½œæµæ‰§è¡Œæ‘˜è¦: æˆåŠŸå¤„ç†{}ä¸ªæ–‡ä»¶ï¼Œè¯†åˆ«{}ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œç”Ÿæˆ{}ä»½è°ƒç ”æŠ¥å‘Šå’Œ{}ä¸ªæ–‡æ¡£æ–‡ä»¶ã€‚",
            preprocessing_result.project_structure.total_files,
            preprocessing_result.core_components.len(),
            research_result.reports.len(),
            documentation_result.documents.len()
        )
    }

    fn generate_markdown_summary(
        &self,
        preprocessing_result: &crate::agents::preprocessing_agent::PreprocessingResult,
        research_result: &ResearchResult,
        documentation_result: &DocumentationResult,
    ) -> String {
        format!(
            r#"# Litho å¼•æ“æ‰§è¡Œæ‘˜è¦

## é¡¹ç›®ä¿¡æ¯
- **é¡¹ç›®è·¯å¾„**: {}
- **ç”Ÿæˆæ—¶é—´**: {}
- **æ€»å¤„ç†æ—¶é—´**: {:.2}ç§’

## é¢„å¤„ç†é˜¶æ®µç»“æœ
- **æ€»æ–‡ä»¶æ•°**: {}
- **æ€»ç›®å½•æ•°**: {}
- **æ ¸å¿ƒç»„ä»¶æ•°**: {}
- **å¤„ç†æ—¶é—´**: {:.2}ç§’

### æ ¸å¿ƒç»„ä»¶åˆ—è¡¨
{}

## è°ƒç ”é˜¶æ®µç»“æœ
- **ç”ŸæˆæŠ¥å‘Šæ•°**: {}
- **å¤„ç†æ—¶é—´**: {:.2}ç§’

### è°ƒç ”æŠ¥å‘Š
{}

## æ–‡æ¡£ç”Ÿæˆé˜¶æ®µç»“æœ
- **ç”Ÿæˆæ–‡æ¡£æ•°**: {}
- **å¤„ç†æ—¶é—´**: {:.2}ç§’

### ç”Ÿæˆçš„æ–‡æ¡£
{}

## æ¶æ„æ´å¯Ÿ
{}

---
*ç”± DeepWiki-RS è‡ªåŠ¨ç”Ÿæˆ*
"#,
            self.config.project_path.display(),
            chrono::Utc::now().format("%Y-%m-%d %H:%M:%S UTC"),
            preprocessing_result.processing_time,
            preprocessing_result.project_structure.total_files,
            preprocessing_result.project_structure.total_directories,
            preprocessing_result.core_components.len(),
            preprocessing_result.processing_time,
            preprocessing_result
                .core_components
                .iter()
                .map(|c| format!(
                    "- **{}** ({}): {}",
                    c.name,
                    c.component_type,
                    c.file_path.display()
                ))
                .collect::<Vec<_>>()
                .join("\n"),
            research_result.reports.len(),
            0.0, // research time placeholder
            research_result
                .reports
                .iter()
                .map(|r| format!("- **{}**: {}", r.title, r.summary))
                .collect::<Vec<_>>()
                .join("\n"),
            documentation_result.documents.len(),
            0.0, // documentation time placeholder
            documentation_result
                .documents
                .iter()
                .map(|d| format!("- **{}** ({})", d.title, d.filename))
                .collect::<Vec<_>>()
                .join("\n"),
            preprocessing_result.architecture_insights.join("\n- ")
        )
    }
}
