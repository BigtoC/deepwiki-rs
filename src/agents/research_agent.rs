use crate::llm::LLMClient;
use anyhow::Result;
use serde::{Deserialize, Serialize};
use std::time::Instant;

use crate::agents::preprocessing_agent::PreprocessingResult;
use crate::cache::CacheManager;
use crate::config::Config;
use crate::extractors::{ResearchExtractor, ResearchReport, AIResearchEnhancement, AIComprehensiveInsights, AIRecommendations};

/// è°ƒç ”Agent
pub struct ResearchAgent {
    llm_client: LLMClient,
    config: Config,
    cache_manager: CacheManager,
    research_extractor: ResearchExtractor,
}

/// è°ƒç ”ç»“æœ
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct ResearchResult {
    pub reports: Vec<ResearchReport>,
    pub insights: Vec<String>,
    pub recommendations: Vec<String>,
    pub processing_time: f64,
    pub summary: String,
}

impl ResearchAgent {
    pub async fn new(config: Config) -> Result<Self> {
        let llm_client = LLMClient::new(config.clone())?;
        let cache_manager = CacheManager::new(config.cache.clone());
        let research_extractor = ResearchExtractor::new(cache_manager.clone());

        Ok(Self {
            llm_client,
            config,
            cache_manager,
            research_extractor,
        })
    }

    /// ç”Ÿæˆè°ƒç ”æ–‡æ¡£
    pub async fn generate_research(
        &self,
        preprocessing_result: &PreprocessingResult,
    ) -> Result<ResearchResult> {
        let start_time = Instant::now();

        println!("ğŸ” å¼€å§‹è°ƒç ”æ–‡æ¡£ç”Ÿæˆ...");

        // 1. ç”ŸæˆåŸºç¡€è°ƒç ”æŠ¥å‘Š
        println!("ğŸ“Š ç”ŸæˆåŸºç¡€è°ƒç ”æŠ¥å‘Š...");
        let mut reports = self
            .research_extractor
            .generate_reports(preprocessing_result)
            .await?;

        // 2. ä½¿ç”¨AIå¢å¼ºè°ƒç ”æŠ¥å‘Š
        println!("ğŸ¤– ä½¿ç”¨AIå¢å¼ºè°ƒç ”æŠ¥å‘Š...");
        for report in &mut reports {
            if let Ok(enhanced_report) = self
                .enhance_report_with_ai(report, preprocessing_result)
                .await
            {
                *report = enhanced_report;
            }
        }

        // 3. ç”Ÿæˆç»¼åˆæ´å¯Ÿ
        println!("ğŸ’¡ ç”Ÿæˆç»¼åˆæ´å¯Ÿ...");
        let insights = self
            .generate_comprehensive_insights(&reports, preprocessing_result)
            .await?;

        // 4. ç”Ÿæˆæ”¹è¿›å»ºè®®
        println!("ğŸ“ ç”Ÿæˆæ”¹è¿›å»ºè®®...");
        let recommendations = self
            .generate_recommendations(&reports, preprocessing_result)
            .await?;

        // 5. ç”Ÿæˆæ‘˜è¦
        let summary = self.generate_research_summary(&reports, &insights, &recommendations);

        let processing_time = start_time.elapsed().as_secs_f64();

        println!("âœ… è°ƒç ”æ–‡æ¡£ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶ {:.2}ç§’", processing_time);

        Ok(ResearchResult {
            reports,
            insights,
            recommendations,
            processing_time,
            summary,
        })
    }

    async fn enhance_report_with_ai(
        &self,
        report: &ResearchReport,
        preprocessing_result: &PreprocessingResult,
    ) -> Result<ResearchReport> {
        // æ„å»ºAIå¢å¼ºæç¤º
        let prompt = self.build_research_enhancement_prompt(report, preprocessing_result);

        // å°è¯•ä»ç¼“å­˜è·å– - ç›´æ¥ä½¿ç”¨promptä½œä¸ºkeyï¼ŒCacheManagerä¼šè‡ªåŠ¨è®¡ç®—hash
        if let Some(cached_report) = self
            .cache_manager
            . get::<ResearchReport>("ai_research", &prompt)
            .await?
        {
            println!("   âœ… ä½¿ç”¨ç¼“å­˜çš„AIè°ƒç ”ç»“æœ: {}", report.title);
            return Ok(cached_report);
        }

        println!("   ğŸ¤– æ­£åœ¨è¿›è¡ŒAIè°ƒç ”åˆ†æ: {}", report.title);

        // æ‰§è¡ŒAIåˆ†æï¼Œä½¿ç”¨extractå‡½æ•°è‡ªåŠ¨æå–ç»“æ„åŒ–æ•°æ®
        let system_msg = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è½¯ä»¶æ¶æ„ç ”ç©¶å‘˜ï¼Œä¸“é—¨æ·±å…¥åˆ†æè½¯ä»¶é¡¹ç›®çš„æ¶æ„ã€è®¾è®¡å’Œè´¨é‡ã€‚è¯·æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚".to_string();
        let ai_enhancement = self
            .llm_client
            .extract::<AIResearchEnhancement>(&system_msg, &prompt)
            .await
            .map_err(|e| anyhow::anyhow!("AIåˆ†æå¤±è´¥: {}", e))?;

        // ä½¿ç”¨AIåˆ†æç»“æœå¢å¼ºæŠ¥å‘Š
        let enhanced_report = self.merge_ai_enhancement_results(report, &ai_enhancement);

        // ç¼“å­˜ç»“æœ - ç›´æ¥ä½¿ç”¨promptä½œä¸ºkey
        self.cache_manager
            .set("ai_research", &prompt, &enhanced_report)
            .await?;

        Ok(enhanced_report)
    }

    fn build_research_enhancement_prompt(
        &self,
        report: &ResearchReport,
        preprocessing_result: &PreprocessingResult,
    ) -> String {
        format!(
            r#"
è¯·æ·±å…¥åˆ†æä»¥ä¸‹è½¯ä»¶é¡¹ç›®çš„è°ƒç ”æŠ¥å‘Šï¼Œå¹¶æä¾›ä¸“ä¸šçš„å¢å¼ºåˆ†æï¼š

## é¡¹ç›®åŸºæœ¬ä¿¡æ¯
- æ–‡ä»¶æ€»æ•°: {}
- æ ¸å¿ƒç»„ä»¶æ•°: {}
- ä¸»è¦æŠ€æœ¯æ ˆ: {}

## å½“å‰è°ƒç ”æŠ¥å‘Š
**æ ‡é¢˜**: {}
**ç±»å‹**: {}
**æ‘˜è¦**: {}

**ç°æœ‰æ´å¯Ÿ**:
{}

**ç°æœ‰å»ºè®®**:
{}

## åˆ†æè¦æ±‚

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œæä¾›ä»¥ä¸‹ç»“æ„åŒ–çš„æ·±åº¦åˆ†æï¼š

1. **æ·±åº¦æ´å¯Ÿ** (deep_insights): åŸºäºé¡¹ç›®ç‰¹å¾ï¼Œæä¾›3-5ä¸ªæ·±å±‚æ¬¡çš„æŠ€æœ¯æ´å¯Ÿï¼Œæ¯ä¸ªæ´å¯Ÿåº”è¯¥å…·ä½“ä¸”æœ‰ä»·å€¼
2. **æ¶æ„è¯„ä¼°** (architecture_assessment): è¯„ä¼°å½“å‰æ¶æ„çš„ä¼˜åŠ¿å’Œæ½œåœ¨é—®é¢˜ï¼Œæä¾›è¯¦ç»†çš„åˆ†æå†…å®¹
3. **æŠ€æœ¯å€ºåŠ¡** (technical_debt): è¯†åˆ«å¯èƒ½å­˜åœ¨çš„æŠ€æœ¯å€ºåŠ¡å’Œé£é™©ç‚¹ï¼Œåˆ—å‡ºå…·ä½“çš„é—®é¢˜
4. **æ”¹è¿›è·¯å¾„** (improvement_paths): æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®å’Œå®æ–½è·¯å¾„ï¼ŒåŒ…å«å¯æ“ä½œçš„æ­¥éª¤
5. **æœ€ä½³å®è·µ** (best_practices): æ¨èç›¸å…³çš„æœ€ä½³å®è·µå’Œè®¾è®¡æ¨¡å¼ï¼Œé€‚åˆå½“å‰é¡¹ç›®

è¯·ç¡®ä¿åˆ†æå†…å®¹ä¸“ä¸šã€å…·ä½“ä¸”æœ‰å®é™…æŒ‡å¯¼ä»·å€¼ã€‚
"#,
            preprocessing_result.project_structure.total_files,
            preprocessing_result.core_components.len(),
            preprocessing_result
                .project_structure
                .file_types
                .keys()
                .take(3)
                .cloned()
                .collect::<Vec<_>>()
                .join(", "),
            report.title,
            report.report_type,
            report.summary,
            report.insights.join("\n- "),
            report.recommendations.join("\n- ")
        )
    }

    fn merge_ai_enhancement_results(
        &self,
        report: &ResearchReport,
        ai_enhancement: &AIResearchEnhancement,
    ) -> ResearchReport {
        let mut enhanced_report = report.clone();

        // åˆå¹¶æ·±åº¦æ´å¯Ÿ
        enhanced_report.insights.extend(ai_enhancement.deep_insights.clone());

        // åˆå¹¶æ”¹è¿›å»ºè®®
        enhanced_report.recommendations.extend(ai_enhancement.improvement_paths.clone());
        enhanced_report.recommendations.extend(ai_enhancement.best_practices.clone());

        // æ›´æ–°å†…å®¹ï¼Œæ·»åŠ AIå¢å¼ºåˆ†æ
        let mut ai_content = String::new();
        
        if !ai_enhancement.architecture_assessment.is_empty() {
            ai_content.push_str(&format!("## æ¶æ„è¯„ä¼°\n{}\n\n", ai_enhancement.architecture_assessment));
        }
        
        if !ai_enhancement.technical_debt.is_empty() {
            ai_content.push_str("## æŠ€æœ¯å€ºåŠ¡åˆ†æ\n");
            for debt in &ai_enhancement.technical_debt {
                ai_content.push_str(&format!("- {}\n", debt));
            }
            ai_content.push('\n');
        }

        if !ai_content.is_empty() {
            enhanced_report.content = format!("{}\n\n## AIå¢å¼ºåˆ†æ\n{}", enhanced_report.content, ai_content);
        }

        enhanced_report
    }

    async fn generate_comprehensive_insights(
        &self,
        reports: &[ResearchReport],
        preprocessing_result: &PreprocessingResult,
    ) -> Result<Vec<String>> {
        let mut insights = Vec::new();

        // ç»¼åˆæ‰€æœ‰æŠ¥å‘Šçš„æ´å¯Ÿ
        for report in reports {
            insights.extend(report.insights.clone());
        }

        // ä½¿ç”¨AIç”Ÿæˆç»¼åˆæ´å¯Ÿ
        let prompt = self.build_comprehensive_insights_prompt(reports, preprocessing_result);
        let system_msg = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è½¯ä»¶æ¶æ„åˆ†æå¸ˆï¼Œä¸“é—¨ç”Ÿæˆé¡¹ç›®çš„ç»¼åˆæ´å¯Ÿã€‚è¯·æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚".to_string();
        
        match self
            .llm_client
            .extract::<AIComprehensiveInsights>(&system_msg, &prompt)
            .await
        {
            Ok(ai_insights) => {
                insights.extend(ai_insights.cross_report_insights);
                insights.extend(ai_insights.quality_insights);
                insights.extend(ai_insights.complexity_insights);
                insights.extend(ai_insights.tech_stack_insights);
            }
            Err(e) => {
                println!("âš ï¸ AIç»¼åˆæ´å¯Ÿç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ: {}", e);
                // å›é€€åˆ°åŸºç¡€åˆ†æ
                insights.extend(self.generate_basic_insights(reports, preprocessing_result));
            }
        }

        Ok(insights)
    }

    fn build_comprehensive_insights_prompt(
        &self,
        reports: &[ResearchReport],
        preprocessing_result: &PreprocessingResult,
    ) -> String {
        let avg_quality = if !preprocessing_result.component_analyses.is_empty() {
            preprocessing_result
                .component_analyses
                .iter()
                .map(|a| a.quality_assessment.overall_score)
                .sum::<f64>()
                / preprocessing_result.component_analyses.len() as f64
        } else {
            0.0
        };

        let avg_complexity = if !preprocessing_result.component_analyses.is_empty() {
            preprocessing_result
                .component_analyses
                .iter()
                .map(|a| a.complexity_metrics.cyclomatic_complexity)
                .sum::<f64>()
                / preprocessing_result.component_analyses.len() as f64
        } else {
            0.0
        };

        format!(
            r#"
è¯·åŸºäºä»¥ä¸‹é¡¹ç›®è°ƒç ”æ•°æ®ï¼Œç”Ÿæˆç»¼åˆæ€§çš„æŠ€æœ¯æ´å¯Ÿï¼š

## é¡¹ç›®æ¦‚å†µ
- æ€»æ–‡ä»¶æ•°: {}
- æ ¸å¿ƒç»„ä»¶æ•°: {}
- è°ƒç ”æŠ¥å‘Šæ•°: {}
- å¹³å‡ä»£ç è´¨é‡: {:.1}/10
- å¹³å‡åœˆå¤æ‚åº¦: {:.1}

## è°ƒç ”æŠ¥å‘Šæ‘˜è¦
{}

## æŠ€æœ¯æ ˆåˆ†æ
ä¸»è¦æŠ€æœ¯: {}

## åˆ†æè¦æ±‚

è¯·æä¾›ä»¥ä¸‹å››ä¸ªç»´åº¦çš„ç»¼åˆæ´å¯Ÿï¼š

1. **è·¨æŠ¥å‘Šç»¼åˆæ´å¯Ÿ** (cross_report_insights): åŸºäºæ‰€æœ‰è°ƒç ”æŠ¥å‘Šçš„ç»¼åˆæ€§å‘ç°ï¼Œè¯†åˆ«é¡¹ç›®çš„æ•´ä½“ç‰¹å¾å’Œæ¨¡å¼
2. **è´¨é‡è¯„ä¼°æ´å¯Ÿ** (quality_insights): åŸºäºä»£ç è´¨é‡åˆ†æçš„æ·±åº¦æ´å¯Ÿï¼ŒåŒ…æ‹¬è´¨é‡è¶‹åŠ¿å’Œæ”¹è¿›ç©ºé—´
3. **æ¶æ„å¤æ‚åº¦æ´å¯Ÿ** (complexity_insights): åŸºäºæ¶æ„å¤æ‚åº¦çš„åˆ†æï¼ŒåŒ…æ‹¬å¤æ‚åº¦åˆ†å¸ƒå’Œä¼˜åŒ–å»ºè®®
4. **æŠ€æœ¯æ ˆæ´å¯Ÿ** (tech_stack_insights): åŸºäºæŠ€æœ¯æ ˆçš„åˆ†æï¼ŒåŒ…æ‹¬æŠ€æœ¯é€‰å‹è¯„ä¼°å’Œå‘å±•å»ºè®®

æ¯ä¸ªæ´å¯Ÿåº”è¯¥å…·ä½“ã€æœ‰ä»·å€¼ä¸”å…·æœ‰æŒ‡å¯¼æ„ä¹‰ã€‚
"#,
            preprocessing_result.project_structure.total_files,
            preprocessing_result.core_components.len(),
            reports.len(),
            avg_quality * 10.0,
            avg_complexity,
            reports
                .iter()
                .map(|r| format!("- {}: {}", r.title, r.summary))
                .collect::<Vec<_>>()
                .join("\n"),
            preprocessing_result
                .project_structure
                .file_types
                .keys()
                .take(5)
                .cloned()
                .collect::<Vec<_>>()
                .join(", ")
        )
    }

    fn generate_basic_insights(
        &self,
        reports: &[ResearchReport],
        preprocessing_result: &PreprocessingResult,
    ) -> Vec<String> {
        let mut insights = Vec::new();

        // æ·»åŠ è·¨æŠ¥å‘Šçš„ç»¼åˆæ´å¯Ÿ
        insights.push(format!("é¡¹ç›®åŒ…å« {} ä¸ªè°ƒç ”ç»´åº¦çš„æ·±åº¦åˆ†æ", reports.len()));

        // åŸºäºç»„ä»¶è´¨é‡çš„æ´å¯Ÿ
        let avg_quality = if !preprocessing_result.component_analyses.is_empty() {
            preprocessing_result
                .component_analyses
                .iter()
                .map(|a| a.quality_assessment.overall_score)
                .sum::<f64>()
                / preprocessing_result.component_analyses.len() as f64
        } else {
            0.0
        };

        insights.push(format!(
            "æ•´ä½“ä»£ç è´¨é‡{}ï¼Œå¹³å‡åˆ†æ•° {:.1}/10",
            if avg_quality > 0.7 {
                "ä¼˜ç§€"
            } else if avg_quality > 0.5 {
                "è‰¯å¥½"
            } else {
                "éœ€è¦æ”¹è¿›"
            },
            avg_quality * 10.0
        ));

        // æ¶æ„å¤æ‚åº¦æ´å¯Ÿ
        let total_complexity: f64 = preprocessing_result
            .component_analyses
            .iter()
            .map(|a| a.complexity_metrics.cyclomatic_complexity)
            .sum();
        let avg_complexity = if !preprocessing_result.component_analyses.is_empty() {
            total_complexity / preprocessing_result.component_analyses.len() as f64
        } else {
            0.0
        };

        insights.push(format!(
            "å¹³å‡åœˆå¤æ‚åº¦ä¸º {:.1}ï¼Œ{}",
            avg_complexity,
            if avg_complexity > 10.0 {
                "å»ºè®®é‡æ„å¤æ‚å‡½æ•°"
            } else if avg_complexity > 5.0 {
                "å¤æ‚åº¦é€‚ä¸­"
            } else {
                "ä»£ç ç»“æ„ç®€æ´"
            }
        ));

        insights
    }

    async fn generate_recommendations(
        &self,
        reports: &[ResearchReport],
        preprocessing_result: &PreprocessingResult,
    ) -> Result<Vec<String>> {
        let mut recommendations = Vec::new();

        // ç»¼åˆæ‰€æœ‰æŠ¥å‘Šçš„å»ºè®®
        for report in reports {
            recommendations.extend(report.recommendations.clone());
        }

        // ä½¿ç”¨AIç”Ÿæˆç»¼åˆå»ºè®®
        let prompt = self.build_recommendations_prompt(reports, preprocessing_result);
        let system_msg = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è½¯ä»¶æ¶æ„é¡¾é—®ï¼Œä¸“é—¨ä¸ºé¡¹ç›®æä¾›æ”¹è¿›å»ºè®®ã€‚è¯·æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¿”å›å»ºè®®ã€‚".to_string();
        
        match self
            .llm_client
            .extract::<AIRecommendations>(&system_msg, &prompt)
            .await
        {
            Ok(ai_recommendations) => {
                recommendations.extend(ai_recommendations.architecture_recommendations);
                recommendations.extend(ai_recommendations.quality_recommendations);
                recommendations.extend(ai_recommendations.performance_recommendations);
                recommendations.extend(ai_recommendations.maintainability_recommendations);
            }
            Err(e) => {
                println!("âš ï¸ AIå»ºè®®ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€å»ºè®®: {}", e);
                // å›é€€åˆ°åŸºç¡€å»ºè®®
                recommendations.extend(self.generate_basic_recommendations(reports, preprocessing_result));
            }
        }

        // å»é‡
        recommendations.sort();
        recommendations.dedup();

        Ok(recommendations)
    }

    fn build_recommendations_prompt(
        &self,
        reports: &[ResearchReport],
        preprocessing_result: &PreprocessingResult,
    ) -> String {
        let low_quality_components = preprocessing_result
            .component_analyses
            .iter()
            .filter(|a| a.quality_assessment.overall_score < 0.5)
            .count();

        let high_complexity_components = preprocessing_result
            .component_analyses
            .iter()
            .filter(|a| a.complexity_metrics.cyclomatic_complexity > 10.0)
            .count();

        format!(
            r#"
è¯·åŸºäºä»¥ä¸‹é¡¹ç›®åˆ†ææ•°æ®ï¼Œç”Ÿæˆå…·ä½“çš„æ”¹è¿›å»ºè®®ï¼š

## é¡¹ç›®æ¦‚å†µ
- æ€»æ–‡ä»¶æ•°: {}
- æ ¸å¿ƒç»„ä»¶æ•°: {}
- ä½è´¨é‡ç»„ä»¶æ•°: {}
- é«˜å¤æ‚åº¦ç»„ä»¶æ•°: {}

## è°ƒç ”æŠ¥å‘Šå»ºè®®æ±‡æ€»
{}

## é¡¹ç›®ç‰¹å¾
- ä¸»è¦æŠ€æœ¯æ ˆ: {}
- é¡¹ç›®è§„æ¨¡: {}

## å»ºè®®è¦æ±‚

è¯·æä¾›ä»¥ä¸‹å››ä¸ªç»´åº¦çš„å…·ä½“æ”¹è¿›å»ºè®®ï¼š

1. **æ¶æ„æ”¹è¿›å»ºè®®** (architecture_recommendations): é’ˆå¯¹æ¶æ„è®¾è®¡çš„å…·ä½“æ”¹è¿›å»ºè®®ï¼ŒåŒ…æ‹¬æ¨¡å—åŒ–ã€è§£è€¦ç­‰
2. **ä»£ç è´¨é‡æ”¹è¿›å»ºè®®** (quality_recommendations): é’ˆå¯¹ä»£ç è´¨é‡çš„å…·ä½“æ”¹è¿›å»ºè®®ï¼ŒåŒ…æ‹¬é‡æ„ã€æµ‹è¯•ç­‰
3. **æ€§èƒ½ä¼˜åŒ–å»ºè®®** (performance_recommendations): é’ˆå¯¹æ€§èƒ½ä¼˜åŒ–çš„å…·ä½“å»ºè®®ï¼ŒåŒ…æ‹¬ç®—æ³•ã€èµ„æºä½¿ç”¨ç­‰
4. **ç»´æŠ¤æ€§æ”¹è¿›å»ºè®®** (maintainability_recommendations): é’ˆå¯¹ä»£ç ç»´æŠ¤æ€§çš„æ”¹è¿›å»ºè®®ï¼ŒåŒ…æ‹¬æ–‡æ¡£ã€è§„èŒƒç­‰

æ¯ä¸ªå»ºè®®åº”è¯¥å…·ä½“ã€å¯æ“ä½œä¸”æœ‰æ˜ç¡®çš„å®æ–½è·¯å¾„ã€‚
"#,
            preprocessing_result.project_structure.total_files,
            preprocessing_result.core_components.len(),
            low_quality_components,
            high_complexity_components,
            reports
                .iter()
                .flat_map(|r| &r.recommendations)
                .take(10)
                .map(|r| format!("- {}", r))
                .collect::<Vec<_>>()
                .join("\n"),
            preprocessing_result
                .project_structure
                .file_types
                .keys()
                .take(3)
                .cloned()
                .collect::<Vec<_>>()
                .join(", "),
            if preprocessing_result.project_structure.total_files > 100 {
                "å¤§å‹é¡¹ç›®"
            } else if preprocessing_result.project_structure.total_files > 50 {
                "ä¸­å‹é¡¹ç›®"
            } else {
                "å°å‹é¡¹ç›®"
            }
        )
    }

    fn generate_basic_recommendations(
        &self,
        _reports: &[ResearchReport],
        preprocessing_result: &PreprocessingResult,
    ) -> Vec<String> {
        let mut recommendations = Vec::new();

        // æ·»åŠ åŸºäºæ•´ä½“åˆ†æçš„å»ºè®®
        if preprocessing_result.core_components.len() > 20 {
            recommendations.push("è€ƒè™‘è¿›ä¸€æ­¥æ¨¡å—åŒ–ï¼Œå°†ç›¸å…³ç»„ä»¶ç»„ç»‡åˆ°å­æ¨¡å—ä¸­".to_string());
        }

        if preprocessing_result.project_structure.total_files > 100 {
            recommendations.push("å»ºè®®å»ºç«‹æ¸…æ™°çš„ä»£ç ç»„ç»‡è§„èŒƒå’Œæ–‡æ¡£".to_string());
        }

        // åŸºäºè´¨é‡åˆ†æçš„å»ºè®®
        let low_quality_components = preprocessing_result
            .component_analyses
            .iter()
            .filter(|a| a.quality_assessment.overall_score < 0.5)
            .count();

        if low_quality_components > 0 {
            recommendations.push(format!(
                "ä¼˜å…ˆé‡æ„ {} ä¸ªè´¨é‡è¾ƒä½çš„ç»„ä»¶",
                low_quality_components
            ));
        }

        recommendations
    }

    fn generate_research_summary(
        &self,
        reports: &[ResearchReport],
        insights: &[String],
        recommendations: &[String],
    ) -> String {
        format!(
            r#"è°ƒç ”æ–‡æ¡£ç”Ÿæˆæ‘˜è¦:

ğŸ“Š è°ƒç ”æŠ¥å‘Š:
- ç”ŸæˆæŠ¥å‘Šæ•°: {}
- ä¸»è¦æŠ¥å‘Šç±»å‹: {}

ğŸ’¡ å…³é”®æ´å¯Ÿ:
- æ€»æ´å¯Ÿæ•°: {}
- æ ¸å¿ƒå‘ç°: {}

ğŸ“ æ”¹è¿›å»ºè®®:
- æ€»å»ºè®®æ•°: {}
- ä¼˜å…ˆå»ºè®®: {}

ğŸ¯ è°ƒç ”ç»“è®º:
é¡¹ç›®æ•´ä½“{}ï¼Œå»ºè®®é‡ç‚¹å…³æ³¨{}ã€‚"#,
            reports.len(),
            reports
                .iter()
                .map(|r| r.report_type.as_str())
                .collect::<Vec<_>>()
                .join(", "),
            insights.len(),
            insights.first().unwrap_or(&"æ— ".to_string()),
            recommendations.len(),
            recommendations.first().unwrap_or(&"æ— ".to_string()),
            if reports.iter().any(|r| r.priority > 0.8) {
                "æ¶æ„è®¾è®¡è‰¯å¥½"
            } else {
                "æœ‰æ”¹è¿›ç©ºé—´"
            },
            if recommendations.len() > 3 {
                "ä»£ç è´¨é‡æå‡"
            } else {
                "æ¶æ„ä¼˜åŒ–"
            }
        )
    }
}