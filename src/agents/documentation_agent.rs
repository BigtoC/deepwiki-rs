use anyhow::Result;
use crate::llm::LLMClient;
use serde::{Deserialize, Serialize};
use std::time::Instant;

use crate::cache::CacheManager;
use crate::config::Config;
use crate::agents::{preprocessing_agent::PreprocessingResult, research_agent::ResearchResult};
use crate::extractors::{DocumentationExtractor, C4Documentation};
use crate::utils::FileUtils;

/// æ–‡æ¡£ç”ŸæˆAgent
pub struct DocumentationAgent {
    llm_client: LLMClient,
    config: Config,
    cache_manager: CacheManager,
    documentation_extractor: DocumentationExtractor,
}

/// æ–‡æ¡£ç”Ÿæˆç»“æœ
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct DocumentationResult {
    pub documents: Vec<Document>,
    pub c4_documentation: C4Documentation,
    pub processing_time: f64,
    pub summary: String,
}

/// æ–‡æ¡£ä¿¡æ¯
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct Document {
    pub title: String,
    pub filename: String,
    pub content: String,
    pub doc_type: String,
    pub priority: f64,
}

impl DocumentationAgent {
    pub async fn new(config: Config) -> Result<Self> {
        let llm_client = LLMClient::new(config.llm.clone())?;
        let cache_manager = CacheManager::new(config.cache.clone());
        let documentation_extractor = DocumentationExtractor::new(cache_manager.clone());

        Ok(Self {
            llm_client,
            config,
            cache_manager,
            documentation_extractor,
        })
    }

    /// ç”ŸæˆçŸ¥è¯†åº“æ–‡æ¡£
    pub async fn generate_documentation(
        &self,
        preprocessing_result: &PreprocessingResult,
        research_result: &ResearchResult,
    ) -> Result<DocumentationResult> {
        let start_time = Instant::now();
        
        println!("ğŸ“– å¼€å§‹çŸ¥è¯†åº“æ–‡æ¡£ç”Ÿæˆ...");

        // 1. ç”ŸæˆåŸºç¡€æ–‡æ¡£
        println!("ğŸ“„ ç”ŸæˆåŸºç¡€æ–‡æ¡£...");
        let mut documents = self.documentation_extractor
            .generate_all_documents(preprocessing_result, &research_result.reports)
            .await?;

        // 2. ç”ŸæˆC4æ¶æ„æ–‡æ¡£
        println!("ğŸ—ï¸ ç”ŸæˆC4æ¶æ„æ–‡æ¡£...");
        let c4_documentation = self.documentation_extractor
            .generate_c4_documentation(preprocessing_result, &research_result.reports)
            .await?;

        // 3. ä½¿ç”¨AIå¢å¼ºæ–‡æ¡£å†…å®¹
        println!("ğŸ¤– ä½¿ç”¨AIå¢å¼ºæ–‡æ¡£å†…å®¹...");
        for document in &mut documents {
            if let Ok(enhanced_doc) = self.enhance_document_with_ai(document, preprocessing_result, research_result).await {
                *document = enhanced_doc;
            }
        }

        // 4. ç”Ÿæˆé¢å¤–çš„ä¸“ä¸šæ–‡æ¡£
        println!("ğŸ“š ç”Ÿæˆä¸“ä¸šæ–‡æ¡£...");
        let additional_docs = self.generate_professional_documents(preprocessing_result, research_result).await?;
        documents.extend(additional_docs);

        // è½¬æ¢DocumentInfoåˆ°Document
        let final_documents: Vec<Document> = documents.into_iter().map(|doc_info| Document {
            title: doc_info.title,
            filename: doc_info.filename,
            content: doc_info.content,
            doc_type: doc_info.doc_type,
            priority: doc_info.priority,
        }).collect();

        // 5. ä¿å­˜æ‰€æœ‰æ–‡æ¡£
        println!("ğŸ’¾ ä¿å­˜æ–‡æ¡£æ–‡ä»¶...");
        self.save_documents(&final_documents).await?;

        let processing_time = start_time.elapsed().as_secs_f64();
        let summary = self.generate_documentation_summary(&final_documents, &c4_documentation);

        println!("âœ… çŸ¥è¯†åº“æ–‡æ¡£ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶ {:.2}ç§’", processing_time);

        Ok(DocumentationResult {
            documents: final_documents,
            c4_documentation,
            processing_time,
            summary,
        })
    }

    async fn enhance_document_with_ai(
        &self,
        document: &crate::extractors::documentation_extractor::DocumentInfo,
        preprocessing_result: &PreprocessingResult,
        research_result: &ResearchResult,
    ) -> Result<crate::extractors::documentation_extractor::DocumentInfo> {
        // æ„å»ºAIå¢å¼ºæç¤º
        let prompt = self.build_documentation_enhancement_prompt(document, preprocessing_result, research_result);

        // å°è¯•ä»ç¼“å­˜è·å– - ç›´æ¥ä½¿ç”¨promptä½œä¸ºkeyï¼ŒCacheManagerä¼šè‡ªåŠ¨è®¡ç®—hash
        if let Some(cached_doc) = self.cache_manager
            .get::<crate::extractors::documentation_extractor::DocumentInfo>("ai_documentation", &prompt)
            .await?
        {
            println!("   âœ… ä½¿ç”¨ç¼“å­˜çš„AIæ–‡æ¡£ç»“æœ: {}", document.title);
            return Ok(cached_doc);
        }

        println!("   ğŸ¤– æ­£åœ¨è¿›è¡ŒAIæ–‡æ¡£å¢å¼º: {}", document.title);

        // æ‰§è¡ŒAIåˆ†æ
        let system_msg = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ–‡æ¡£ç¼–å†™ä¸“å®¶ï¼Œä¸“é—¨åˆ›å»ºæ¸…æ™°ã€å…¨é¢ã€æ˜“æ‡‚çš„è½¯ä»¶é¡¹ç›®æ–‡æ¡£ã€‚".to_string();
        let prompt_clone = prompt.clone();
        let ai_response = self.llm_client
            .chat_with_system(&system_msg, &prompt_clone)
            .await
            .map_err(|e| anyhow::anyhow!("AIåˆ†æå¤±è´¥: {}", e))?;

        // è§£æAIå“åº”å¹¶å¢å¼ºæ–‡æ¡£
        let mut enhanced_document = document.clone();
        self.parse_ai_documentation_response(&ai_response, &mut enhanced_document);

        // ç¼“å­˜ç»“æœ - ç›´æ¥ä½¿ç”¨promptä½œä¸ºkey
        self.cache_manager
            .set("ai_documentation", &prompt, &enhanced_document)
            .await?;

        Ok(enhanced_document)
    }

    fn build_documentation_enhancement_prompt(
        &self,
        document: &crate::extractors::documentation_extractor::DocumentInfo,
        preprocessing_result: &PreprocessingResult,
        research_result: &ResearchResult,
    ) -> String {
        format!(
            r#"
è¯·å¢å¼ºä»¥ä¸‹æŠ€æœ¯æ–‡æ¡£ï¼Œä½¿å…¶æ›´åŠ ä¸“ä¸šã€å…¨é¢å’Œæ˜“äºç†è§£ï¼š

## é¡¹ç›®èƒŒæ™¯
- é¡¹ç›®æ–‡ä»¶æ•°: {}
- æ ¸å¿ƒç»„ä»¶æ•°: {}
- è°ƒç ”æŠ¥å‘Šæ•°: {}

## å½“å‰æ–‡æ¡£
**æ ‡é¢˜**: {}
**ç±»å‹**: {}
**ä¼˜å…ˆçº§**: {:.1}

**å½“å‰å†…å®¹**:
{}

## è°ƒç ”æ´å¯Ÿ
{}

## è¯·æä¾›ä»¥ä¸‹å¢å¼ºï¼š

1. **å†…å®¹å®Œå–„**: è¡¥å……ç¼ºå¤±çš„é‡è¦ä¿¡æ¯å’Œç»†èŠ‚
2. **ç»“æ„ä¼˜åŒ–**: æ”¹è¿›æ–‡æ¡£ç»“æ„å’Œç»„ç»‡æ–¹å¼
3. **å®ç”¨æ€§**: æ·»åŠ å®é™…çš„ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µ
4. **å¯è¯»æ€§**: æé«˜æ–‡æ¡£çš„å¯è¯»æ€§å’Œä¸“ä¸šæ€§
5. **å®Œæ•´æ€§**: ç¡®ä¿æ–‡æ¡£æ¶µç›–æ‰€æœ‰å¿…è¦çš„æ–¹é¢

è¯·ä¿æŒMarkdownæ ¼å¼ï¼Œå¹¶ç¡®ä¿å†…å®¹å‡†ç¡®ã€å®ç”¨ã€‚
"#,
            preprocessing_result.project_structure.total_files,
            preprocessing_result.core_components.len(),
            research_result.reports.len(),
            document.title,
            document.doc_type,
            document.priority,
            document.content,
            research_result.insights.join("\n- ")
        )
    }

    fn parse_ai_documentation_response(&self, response: &str, document: &mut crate::extractors::documentation_extractor::DocumentInfo) {
        // å¦‚æœAIå“åº”åŒ…å«å®Œæ•´çš„æ–‡æ¡£å†…å®¹ï¼Œåˆ™æ›¿æ¢
        if response.len() > document.content.len() && response.contains("# ") {
            document.content = response.to_string();
        } else {
            // å¦åˆ™è¿½åŠ å¢å¼ºå†…å®¹
            document.content = format!("{}\n\n## AIå¢å¼ºå†…å®¹\n\n{}", document.content, response);
        }
    }

    async fn generate_professional_documents(
        &self,
        preprocessing_result: &PreprocessingResult,
        research_result: &ResearchResult,
    ) -> Result<Vec<crate::extractors::documentation_extractor::DocumentInfo>> {
        let mut documents = Vec::new();

        // ç”ŸæˆæŠ€æœ¯è§„èŒƒæ–‡æ¡£
        documents.push(self.generate_technical_specification(preprocessing_result, research_result).await?);

        // ç”Ÿæˆæµ‹è¯•æŒ‡å—
        documents.push(self.generate_testing_guide(preprocessing_result).await?);

        // ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š
        documents.push(self.generate_performance_analysis(preprocessing_result).await?);

        // ç”Ÿæˆå®‰å…¨åˆ†ææŠ¥å‘Š
        documents.push(self.generate_security_analysis(preprocessing_result).await?);

        Ok(documents)
    }

    async fn generate_technical_specification(
        &self,
        preprocessing_result: &PreprocessingResult,
        research_result: &ResearchResult,
    ) -> Result<crate::extractors::documentation_extractor::DocumentInfo> {
        use crate::utils::MarkdownUtils;

        let mut content = String::new();
        
        content.push_str(&MarkdownUtils::heading(1, "æŠ€æœ¯è§„èŒƒ"));
        content.push_str("\n");

        // æŠ€æœ¯æ ˆè§„èŒƒ
        content.push_str(&MarkdownUtils::heading(2, "æŠ€æœ¯æ ˆ"));
        let tech_stack: Vec<String> = preprocessing_result.project_structure.file_types
            .iter()
            .map(|(ext, count)| format!("- **{}**: {} ä¸ªæ–‡ä»¶", ext.to_uppercase(), count))
            .collect();
        content.push_str(&tech_stack.join("\n"));
        content.push_str("\n\n");

        // æ¶æ„è§„èŒƒ
        content.push_str(&MarkdownUtils::heading(2, "æ¶æ„è§„èŒƒ"));
        content.push_str("## ç»„ä»¶è®¾è®¡åŸåˆ™\n\n");
        content.push_str("- å•ä¸€èŒè´£åŸåˆ™\n");
        content.push_str("- å¼€é—­åŸåˆ™\n");
        content.push_str("- ä¾èµ–å€’ç½®åŸåˆ™\n\n");

        // ç¼–ç è§„èŒƒ
        content.push_str(&MarkdownUtils::heading(2, "ç¼–ç è§„èŒƒ"));
        content.push_str("### å‘½åè§„èŒƒ\n");
        content.push_str("- ä½¿ç”¨æœ‰æ„ä¹‰çš„å˜é‡å’Œå‡½æ•°å\n");
        content.push_str("- éµå¾ªè¯­è¨€ç‰¹å®šçš„å‘½åçº¦å®š\n");
        content.push_str("- é¿å…ç¼©å†™å’Œæ¨¡ç³Šçš„åç§°\n\n");

        // è´¨é‡æ ‡å‡†
        content.push_str(&MarkdownUtils::heading(2, "è´¨é‡æ ‡å‡†"));
        let avg_quality = if !preprocessing_result.component_analyses.is_empty() {
            preprocessing_result.component_analyses.iter()
                .map(|a| a.quality_assessment.overall_score)
                .sum::<f64>() / preprocessing_result.component_analyses.len() as f64
        } else {
            0.0
        };
        content.push_str(&format!("- å½“å‰å¹³å‡è´¨é‡åˆ†æ•°: {:.1}/10\n", avg_quality * 10.0));
        content.push_str("- ç›®æ ‡è´¨é‡åˆ†æ•°: 8.0/10\n");
        content.push_str("- ä»£ç è¦†ç›–ç‡ç›®æ ‡: 80%\n\n");

        Ok(crate::extractors::documentation_extractor::DocumentInfo {
            title: "æŠ€æœ¯è§„èŒƒ".to_string(),
            filename: "technical_specification.md".to_string(),
            content: MarkdownUtils::document("æŠ€æœ¯è§„èŒƒ", &content),
            doc_type: "specification".to_string(),
            priority: 0.8,
        })
    }

    async fn generate_testing_guide(&self, preprocessing_result: &PreprocessingResult) -> Result<crate::extractors::documentation_extractor::DocumentInfo> {
        use crate::utils::MarkdownUtils;

        let mut content = String::new();
        
        content.push_str(&MarkdownUtils::heading(1, "æµ‹è¯•æŒ‡å—"));
        content.push_str("\n");

        content.push_str(&MarkdownUtils::heading(2, "æµ‹è¯•ç­–ç•¥"));
        content.push_str("æœ¬é¡¹ç›®é‡‡ç”¨å¤šå±‚æ¬¡çš„æµ‹è¯•ç­–ç•¥ï¼š\n\n");
        
        let test_levels = vec![
            "å•å…ƒæµ‹è¯• - æµ‹è¯•å•ä¸ªç»„ä»¶çš„åŠŸèƒ½",
            "é›†æˆæµ‹è¯• - æµ‹è¯•ç»„ä»¶é—´çš„äº¤äº’",
            "ç³»ç»Ÿæµ‹è¯• - æµ‹è¯•æ•´ä¸ªç³»ç»Ÿçš„åŠŸèƒ½",
            "æ€§èƒ½æµ‹è¯• - æµ‹è¯•ç³»ç»Ÿçš„æ€§èƒ½è¡¨ç°"
        ];
        content.push_str(&MarkdownUtils::list(&test_levels.iter().map(|s| *s).collect::<Vec<_>>(), false));

        content.push_str(&MarkdownUtils::heading(2, "æµ‹è¯•è¦†ç›–ç‡"));
        content.push_str(&format!(
            "- æ ¸å¿ƒç»„ä»¶æ•°: {}\n- å»ºè®®æµ‹è¯•è¦†ç›–ç‡: 80%\n- å…³é”®ç»„ä»¶è¦†ç›–ç‡: 95%\n\n",
            preprocessing_result.core_components.len()
        ));

        content.push_str(&MarkdownUtils::heading(2, "æµ‹è¯•å·¥å…·"));
        content.push_str("æ¨èä½¿ç”¨ä»¥ä¸‹æµ‹è¯•å·¥å…·ï¼š\n\n");
        content.push_str("- å•å…ƒæµ‹è¯•æ¡†æ¶\n");
        content.push_str("- æ¨¡æ‹Ÿå·¥å…·\n");
        content.push_str("- æ€§èƒ½æµ‹è¯•å·¥å…·\n");
        content.push_str("- ä»£ç è¦†ç›–ç‡å·¥å…·\n\n");

        Ok(crate::extractors::documentation_extractor::DocumentInfo {
            title: "æµ‹è¯•æŒ‡å—".to_string(),
            filename: "testing_guide.md".to_string(),
            content: MarkdownUtils::document("æµ‹è¯•æŒ‡å—", &content),
            doc_type: "guide".to_string(),
            priority: 0.7,
        })
    }

    async fn generate_performance_analysis(&self, preprocessing_result: &PreprocessingResult) -> Result<crate::extractors::documentation_extractor::DocumentInfo> {
        use crate::utils::MarkdownUtils;

        let mut content = String::new();
        
        content.push_str(&MarkdownUtils::heading(1, "æ€§èƒ½åˆ†ææŠ¥å‘Š"));
        content.push_str("\n");

        content.push_str(&MarkdownUtils::heading(2, "æ€§èƒ½æ¦‚è§ˆ"));
        
        // è®¡ç®—å¹³å‡å¤æ‚åº¦
        let avg_complexity = if !preprocessing_result.component_analyses.is_empty() {
            preprocessing_result.component_analyses.iter()
                .map(|a| a.complexity_metrics.cyclomatic_complexity)
                .sum::<f64>() / preprocessing_result.component_analyses.len() as f64
        } else {
            0.0
        };

        content.push_str(&format!(
            "- å¹³å‡åœˆå¤æ‚åº¦: {:.1}\n- æ€»ä»£ç è¡Œæ•°: {}\n- æ ¸å¿ƒç»„ä»¶æ•°: {}\n\n",
            avg_complexity,
            preprocessing_result.component_analyses.iter()
                .map(|a| a.complexity_metrics.lines_of_code)
                .sum::<usize>(),
            preprocessing_result.core_components.len()
        ));

        content.push_str(&MarkdownUtils::heading(2, "æ€§èƒ½ç“¶é¢ˆ"));
        let high_complexity_components: Vec<_> = preprocessing_result.component_analyses.iter()
            .filter(|a| a.complexity_metrics.cyclomatic_complexity > 10.0)
            .collect();

        if high_complexity_components.is_empty() {
            content.push_str("æœªå‘ç°æ˜æ˜¾çš„æ€§èƒ½ç“¶é¢ˆã€‚\n\n");
        } else {
            content.push_str("å‘ç°ä»¥ä¸‹é«˜å¤æ‚åº¦ç»„ä»¶ï¼š\n\n");
            for component in high_complexity_components {
                content.push_str(&format!(
                    "- **{}**: å¤æ‚åº¦ {:.1}\n",
                    component.component.name,
                    component.complexity_metrics.cyclomatic_complexity
                ));
            }
            content.push_str("\n");
        }

        content.push_str(&MarkdownUtils::heading(2, "ä¼˜åŒ–å»ºè®®"));
        let optimization_suggestions = vec![
            "é‡æ„é«˜å¤æ‚åº¦å‡½æ•°",
            "ä¼˜åŒ–ç®—æ³•å¤æ‚åº¦",
            "å‡å°‘ä¸å¿…è¦çš„è®¡ç®—",
            "ä½¿ç”¨ç¼“å­˜æœºåˆ¶"
        ];
        content.push_str(&MarkdownUtils::list(&optimization_suggestions.iter().map(|s| *s).collect::<Vec<_>>(), false));

        Ok(crate::extractors::documentation_extractor::DocumentInfo {
            title: "æ€§èƒ½åˆ†ææŠ¥å‘Š".to_string(),
            filename: "performance_analysis.md".to_string(),
            content: MarkdownUtils::document("æ€§èƒ½åˆ†ææŠ¥å‘Š", &content),
            doc_type: "analysis".to_string(),
            priority: 0.6,
        })
    }

    async fn generate_security_analysis(&self, preprocessing_result: &PreprocessingResult) -> Result<crate::extractors::documentation_extractor::DocumentInfo> {
        use crate::utils::MarkdownUtils;

        let mut content = String::new();
        
        content.push_str(&MarkdownUtils::heading(1, "å®‰å…¨åˆ†ææŠ¥å‘Š"));
        content.push_str("\n");

        content.push_str(&MarkdownUtils::heading(2, "å®‰å…¨æ¦‚è§ˆ"));
        content.push_str("æœ¬æŠ¥å‘Šåˆ†æé¡¹ç›®çš„å®‰å…¨ç‰¹å¾å’Œæ½œåœ¨é£é™©ã€‚\n\n");

        content.push_str(&MarkdownUtils::heading(2, "å®‰å…¨æ£€æŸ¥é¡¹"));
        let security_checks = vec![
            "è¾“å…¥éªŒè¯å’Œæ¸…ç†",
            "èº«ä»½è®¤è¯å’Œæˆæƒ",
            "æ•°æ®åŠ å¯†å’Œä¿æŠ¤",
            "é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•",
            "ä¾èµ–é¡¹å®‰å…¨æ€§"
        ];
        content.push_str(&MarkdownUtils::list(&security_checks.iter().map(|s| *s).collect::<Vec<_>>(), false));

        content.push_str(&MarkdownUtils::heading(2, "é£é™©è¯„ä¼°"));
        content.push_str("åŸºäºä»£ç åˆ†æçš„é£é™©è¯„ä¼°ï¼š\n\n");
        
        // åŸºäºç»„ä»¶åˆ†æè¯„ä¼°é£é™©
        let total_components = preprocessing_result.core_components.len();
        let risk_level = if total_components > 20 {
            "ä¸­ç­‰ - ç»„ä»¶è¾ƒå¤šï¼Œéœ€è¦é‡ç‚¹å…³æ³¨ç»„ä»¶é—´çš„å®‰å…¨è¾¹ç•Œ"
        } else if total_components > 10 {
            "è¾ƒä½ - ç»„ä»¶æ•°é‡é€‚ä¸­ï¼Œå®‰å…¨ç®¡ç†ç›¸å¯¹ç®€å•"
        } else {
            "ä½ - ç»„ä»¶è¾ƒå°‘ï¼Œå®‰å…¨é£é™©å¯æ§"
        };

        content.push_str(&format!("- **æ•´ä½“é£é™©ç­‰çº§**: {}\n\n", risk_level));

        content.push_str(&MarkdownUtils::heading(2, "å®‰å…¨å»ºè®®"));
        let security_recommendations = vec![
            "å®šæœŸè¿›è¡Œå®‰å…¨ä»£ç å®¡æŸ¥",
            "ä½¿ç”¨é™æ€ä»£ç åˆ†æå·¥å…·",
            "å®æ–½å®‰å…¨æµ‹è¯•",
            "å»ºç«‹å®‰å…¨å¼€å‘æµç¨‹",
            "å®šæœŸæ›´æ–°ä¾èµ–é¡¹"
        ];
        content.push_str(&MarkdownUtils::list(&security_recommendations.iter().map(|s| *s).collect::<Vec<_>>(), false));

        Ok(crate::extractors::documentation_extractor::DocumentInfo {
            title: "å®‰å…¨åˆ†ææŠ¥å‘Š".to_string(),
            filename: "security_analysis.md".to_string(),
            content: MarkdownUtils::document("å®‰å…¨åˆ†ææŠ¥å‘Š", &content),
            doc_type: "analysis".to_string(),
            priority: 0.5,
        })
    }

    async fn save_documents(&self, documents: &[Document]) -> Result<()> {
        for document in documents {
            let file_path = self.config.output_path.join(&document.filename);
            FileUtils::write_file_safe(&file_path, &document.content).await?;
        }
        Ok(())
    }

    fn generate_documentation_summary(&self, documents: &[Document], _c4_documentation: &C4Documentation) -> String {
        let doc_types: std::collections::HashMap<String, usize> = documents.iter()
            .fold(std::collections::HashMap::new(), |mut acc, doc| {
                *acc.entry(doc.doc_type.clone()).or_insert(0) += 1;
                acc
            });

        format!(
            r#"çŸ¥è¯†åº“æ–‡æ¡£ç”Ÿæˆæ‘˜è¦:

ğŸ“š ç”Ÿæˆæ–‡æ¡£:
- æ€»æ–‡æ¡£æ•°: {}
- æ–‡æ¡£ç±»å‹: {}

ğŸ“„ æ–‡æ¡£åˆ†å¸ƒ:
{}

ğŸ¯ æ–‡æ¡£è´¨é‡:
- é«˜ä¼˜å…ˆçº§æ–‡æ¡£: {}
- å¹³å‡ä¼˜å…ˆçº§: {:.1}

âœ… æ‰€æœ‰æ–‡æ¡£å·²ä¿å­˜åˆ°è¾“å‡ºç›®å½•"#,
            documents.len(),
            doc_types.keys().cloned().collect::<Vec<_>>().join(", "),
            doc_types.iter()
                .map(|(doc_type, count)| format!("- {}: {} ä¸ª", doc_type, count))
                .collect::<Vec<_>>()
                .join("\n"),
            documents.iter().filter(|d| d.priority > 0.8).count(),
            documents.iter().map(|d| d.priority).sum::<f64>() / documents.len() as f64
        )
    }
}