# 系统边界接口文档

本文档描述了系统的外部调用接口，包括CLI命令、API端点、配置参数等边界机制。

## 命令行接口 (CLI)

### litho

**描述**: DeepWiki-RS 命令行工具，用于自动化分析代码库并生成C4架构文档

**源文件**: `src/cli.rs`

**参数**:

- `project_path` (PathBuf): 必需 - 要分析的项目根目录路径 (默认: `.`)
- `output_path` (PathBuf): 必需 - 生成文档的输出目录路径 (默认: `./litho.docs`)

**选项**:

- `config, c`(PathBuf): 可选 - 指定自定义配置文件路径（TOML格式）
- `name, n`(String): 可选 - 显式指定项目名称，覆盖自动推断结果
- `skip_preprocessing`(bool): 可选 - 跳过代码预处理阶段（如结构提取、语言解析）
- `skip_research`(bool): 可选 - 跳过高层架构调研阶段（领域模块、系统上下文分析）
- `skip_documentation`(bool): 可选 - 跳过最终文档生成阶段
- `verbose, v`(bool): 可选 - 启用详细日志输出，便于调试
- `model_efficient`(String): 可选 - 指定用于常规推理的高效LLM模型名称
- `model_powerful`(String): 可选 - 指定用于复杂推理的高质量LLM模型名称，作为高效模型的备用
- `llm_api_base_url`(String): 可选 - 自定义LLM API的基地址，用于替换默认的ModelScope地址
- `llm_api_key`(String): 可选 - LLM服务的API密钥，用于身份验证
- `max_tokens`(u32): 可选 - LLM单次调用允许的最大token数
- `temperature`(f64): 可选 - LLM生成文本的随机性参数（0.0-1.0），值越低越确定
- `max_parallels`(usize): 可选 - 并发调用LLM的最大数量，控制资源消耗
- `llm_provider`(String): 可选 - 指定LLM提供商（支持：openai, moonshot, deepseek, mistral, openrouter, anthropic, gemini）
- `target_language`(String): 可选 - 生成文档的目标语言（支持：zh, en, ja, ko, de, fr, ru）
- `disable_preset_tools`(bool): 可选 - 禁用预设的LLM工具（如文件读取、目录浏览），强制使用外部工具
- `no_cache`(bool): 可选 - 禁用缓存机制，强制重新执行所有分析步骤
- `force_regenerate`(bool): 可选 - 强制重新生成所有输出，清除现有缓存并重新执行全流程

**使用示例**:

```bash
litho --project-path ./my-project --output-path ./docs
```

```bash
litho -c ./my-config.toml --verbose --target-language zh
```

```bash
litho --llm-provider openai --llm-api-key sk-xxx --model-efficient gpt-4o-mini
```

```bash
litho --skip-research --skip-documentation --verbose
```

```bash
litho --force-regenerate --no-cache
```

## 集成建议

### CLI集成

将litho作为CI/CD流水线的一部分，自动为每个PR生成架构文档。

**示例代码**:

```
steps:
  - name: Generate Architecture Documentation
    uses: actions/checkout@v4
    with:
      repository: ${{ github.repository }}
  - name: Install Rust
    uses: actions-rs/toolchain@v1
    with:
      toolchain: stable
  - name: Build litho
    run: |
      cd ./deepwiki-rs
      cargo build --release
  - name: Run litho
    run: |
      ./deepwiki-rs/target/release/litho \
        --project-path . \
        --output-path ./docs/architecture \
        --target-language en \
        --llm-provider openai \
        --llm-api-key ${{ secrets.LLM_API_KEY }} \
        --verbose
  - name: Upload Documentation
    uses: actions/upload-artifact@v4
    with:
      name: architecture-docs
      path: ./docs/architecture/
```

**最佳实践**:

- 将LLM_API_KEY作为GitHub Secrets安全存储，避免硬编码
- 为litho设置合理的超时时间，避免CI任务长时间挂起
- 在生成文档后，使用diff工具检查文档变更，避免无意义的提交
- 优先使用`--no-cache`或`--force-regenerate`确保文档一致性

### 配置文件管理

使用TOML配置文件统一管理多环境的litho运行参数，实现环境隔离。

**示例代码**:

```
# litho.toml
project_path = "."
output_path = "./docs"
target_language = "zh"

[llm]
provider = "deepseek"
api_base_url = "https://api.deepseek.com/v1"
model_efficient = "deepseek-ai/deepseek-coder-6.7b-instruct"
model_powerful = "deepseek-ai/deepseek-llm-67b-chat"
max_tokens = 65536
temperature = 0.1
max_parallels = 2

[cache]
enabled = true
cache_dir = ".litho/cache"
expire_hours = 168
```

**最佳实践**:

- 为不同项目创建独立的litho.toml配置文件，置于项目根目录
- 在团队中共享litho.toml模板，确保文档生成标准一致
- 将敏感信息（如API_KEY）通过环境变量注入，而非直接写入配置文件
- 对配置文件进行版本控制，追踪配置变更历史

### LLM提供商切换

在不同环境或成本约束下，动态切换LLM提供商以优化性能与成本。

**示例代码**:

```
export LITHO_LLM_API_KEY="your_api_key_here"

# 使用OpenAI进行高质量分析
litho --project-path ./my-project --llm-provider openai --model-powerful gpt-4-turbo

# 使用DeepSeek降低成本进行日常分析
litho --project-path ./my-project --llm-provider deepseek --model-efficient deepseek-coder-6.7b-instruct

# 使用本地部署的模型
litho --project-path ./my-project --llm-provider moonshot --llm-api-base-url http://localhost:8080/v1
```

**最佳实践**:

- 为不同LLM提供商配置独立的API密钥环境变量（如LITHO_OPENAI_KEY, LITHO_DEEPSEEK_KEY）
- 在配置文件中设置fallback策略：model_powerful作为model_efficient的兜底
- 监控各提供商的token消耗和响应时间，定期优化模型选择策略
- 在生产环境中优先使用开源模型（如DeepSeek, Mistral）降低长期成本

### 安全加固

防范API密钥泄露和配置文件篡改等安全风险。

**示例代码**:

```
# .env 文件（不提交到Git）
LITHO_LLM_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# 使用前验证
litho --project-path ./my-project --llm-api-key $LITHO_LLM_API_KEY --verbose

# 配置文件权限控制
chmod 600 litho.toml # 仅所有者可读写
chown $USER:$USER litho.toml
```

**最佳实践**:

- 绝对不要将API密钥硬编码在源码或配置文件中，始终使用环境变量
- 对配置文件设置严格的文件权限（600），避免非授权读取
- 在CI/CD中使用Secrets管理API密钥，禁止在日志中打印敏感信息
- 启用`--verbose`时，确保日志输出不包含API_KEY或敏感路径
- 定期轮换LLM服务的API密钥，遵循最小权限原则


---

**分析置信度**: 9.5/10
